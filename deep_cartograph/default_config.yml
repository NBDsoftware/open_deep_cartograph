# analysis:
#   RMSD:                                       Root mean square deviation analysis
#     analysis_name:                            Name of the analysis
#       title: 'Backbone RMSD'                  Title of the plot
#       selection: 'protein and name CA'        Selection of atoms to compute the RMSD
#       fit_selection: 'protein and name CA'    Selection of atoms to fit the trajectory before computing the RMSD
#   RMSF:                                       Root mean square fluctuation analysis
#     analysis_name:                            Name of the analysis
#       title: 'Backbone RMSF'                  Title of the plot
#       selection: 'protein and name CA'        Selection of atoms to compute the RMSF
#       fit_selection: 'protein and name CA'    Selection of atoms to fit the trajectory before computing the RMSF
# dt_per_frame: 40                              Time in picoseconds per frame in the trajectory

analysis:
  RMSD:
    backbone_rmsd:
      title: 'Backbone RMSD'
      selection: 'protein and name CA'
      fit_selection: 'protein and name CA'
    peptide_rmsd:
      title: 'Peptide RMSD'
      selection: 'resid 625:634 and name CA'
      fit_selection: 'protein and name CA'
  RMSF:
    backbone_rmsf:
      title: 'Backbone RMSF'
      selection: 'protein and name CA'
      fit_selection: 'protein and name CA'
dt_per_frame: 40         

# compute_features:
#   plumed_settings:
#     timeout:                    Time out for the PLUMED calculation in seconds
#     traj_stride:                Trajectory stride for the calculation of features
#     features:                   Definition of features to be included in the PLUMED input file
#       distance_groups:          Groups of distance features.
#         group_name:             Name of the group. All pairwise distances between atoms in the two selections are included
#           first_selection:      Selection of atoms to be included in the first selection of this group (MDAnalysis selection syntax)
#           second_selection:     Selection of atoms to be included in the second selection of this group (MDAnalysis selection syntax)
#           first_stride:         Stride for the first selection. Include only every first_stride-th atom in the selection
#           second_stride:        Stride for the second selection. Include only every second_stride-th atom in the selection
#           skip_neigh_residues:  If True, skip distances involving atoms in consecutive/neighboring residues
#           skip_bonded_atoms:    If True, skip distances between atoms that are bonded
#       dihedral_groups:          Groups of dihedral features.
#         group_name:             Name of the group.
#           selection:            Selection of atoms to be included in this group (MDAnalysis selection syntax)
#           periodic_encoding:    If True, encode the dihedral angle in a periodic function, i.e. the sin and cos of the angle (to obtain smooth features as 0 and 360 degrees correspond to the same angle)
#           search_mode:          Mode to search for the dihedrals. Options: (virtual, protein_backbone, real)
#      distance_to_center_groups: Groups of distances to a geometric center.
#        group_name:              Name of the group. All distances between atoms in the selection and the geometric center are included.
#          selection:             Selection of atoms to compute the distance to the geometric center to (MDAnalysis selection syntax)
#          center_selection:      Selection of atoms to be included in geometric center calculation (MDAnalysis selection syntax) 
#   plumed_environment:      Plumed environment settings
#     bin_path:              Path to the PLUMED binary
#     kernel_path:           Path to the PLUMED kernel library 
#     env_commands:          List of commands to run before running the plumed command

compute_features:
  plumed_settings:
    traj_stride: 1
    features:
      distance_groups:
        ca_dist:
          first_selection: "name CA"
          second_selection: "name CA"
          first_stride: 10
          second_stride: 20
          skip_neigh_residues: True
          skip_bonded_atoms: True
      dihedral_groups:         
        backbn_tors:             
          selection: "name CA"          
          periodic_encoding: True   
          search_mode: virtual
        sidchain_tors:             
          selection: "not backbone and not name H*"         
          periodic_encoding: True   
          search_mode: real
  plumed_environment:                                                               
    bin_path: /eb/x86_64/software/PLUMED/2.9.0-intel-2021b/bin/plumed                 
    kernel_path: /eb/x86_64/software/PLUMED/2.9.0-intel-2021b/lib/libplumedKernel.so  
    env_commands: 
      - "ml PLUMED/2.9.0-intel-2021b"                                                 
      - "unset I_MPI_PMI_LIBRARY" 

# filter_features:
#   filter_settings: 
#     compute_diptest:            Compute Hartigan's dip test
#     compute_entropy:            Compute entropy of the features
#     compute_std:                Compute standard deviation of the features
#     diptest_significance_level: Significance level for the dip test (0 to skip filter, reduce to filter out more features)
#     entropy_quantile:           Entropy quantile to use for filtering (0 to skip filter, reduce to filter out more features)
#     std_quantile:               Standard deviation quantile to use for filtering (0 to skip filter, reduce to filter out more features)

filter_features:       
  filter_settings:
    compute_diptest: True              
    compute_entropy: False             
    compute_std: False                
    diptest_significance_level: 0.05   
    entropy_quantile: 0                
    std_quantile: 0                                                     


# train_colvars:
#   cvs:                           List of Collective Variables to calculate: pca, ae, tica, deep_tica or htica
#   common:                        Common settings for the Collective Variables
#     dimension:                    (int) Number of dimensions to calculate
#     num_subspaces:                (int) Number of subspaces to calculate (only for htica) - increase to reduce the memory usage
#     subspaces_dimension:          (int) Dimension of the subspaces to calculate (only for htica) - reduce to reduce the memory usage
#     features_normalization:       (str) Normalization of the input features, e.g. 'mean_std', 'min_max', null
#     input_colvars:              Settings for the input colvars file reading with the time series of the input features
#       start:                      (int) Start index to read the input features (df.iloc[start:stop:stride])
#       stop:                       (int) Stop index to read the input features (df.iloc[start:stop:stride])
#       stride:                     (int) Stride to read the input features (df.iloc[start:stop:stride])
#     architecture:                 Settings for the architecture of the Collective Variables
#       hidden_layers:              (list) Fully connected hidden layers between the input and latent space, e.g. [15, 15]
#       lag_time:                   (int) Lag time for the Collective Variables
#     training:                    Settings for the training of the Collective Variables (when applicable)
#       general:                    General settings for the training
#         max_tries:                    (int) Maximum number of tries for the training
#         seed:                         (int) Seed for the PyTorch random number generator
#         lengths:                      (list) Lengths of the training and validation sets, e.g. [0.8, 0.2]
#         batch_size:                   (int) Batch size for the training
#         max_epochs:                   (int) Maximum number of epochs for the training
#         dropout:                      (float) Dropout rate for the training
#         shuffle:                      (bool) Shuffle the data before training 
#         check_val_every_n_epoch:      (int) Do a validation check every n epochs
#         save_check_every_n_epoch:     (int) Save the model every n epochs
#       early_stopping:              Settings for the early stopping
#         patience:                     (int) Patience for the early stopping, i.e., the number of validation checks with no improvement after which training will be stopped
#         min_delta:                    (float) Minimum change in the loss function to consider it an improvement
#       optimizer:                   Settings for the optimizer
#         name:                         (str) Name of the optimizer
#         kwargs:                       (dict) Keyword arguments for the optimizer
#       save_loss:                    (bool) Wether to save the training and validation losses after training 
#       plot_loss:                    (bool) Wether to plot the loss after training
#   figures:                          Settings for additional figures
#     fes:                              Settings for the Free Energy Surface calculation
#       compute:                          (bool) Calculate the Free Energy Surface
#       save:                             (bool) Save the calculated Free Energy Surface in .npy files (otherwise it just plots 1D or 2D FES)
#       temperature:                      (int) Temperature in Kelvin
#       bandwidth:                        (float) Bandwidth for the Kernel Density Estimation of the Free Energy Surface
#       num_bins:                         (int) Number of bins for the Kernel Density Estimation of the Free Energy Surface
#       num_blocks:                       (int) Number of blocks for the standard error calculation of the Free Energy Surface
#       max_fes:                          (float) Maximum value for the Free Energy Surface (above which the value is set to NaN)
#     traj_projection:                Settings for the Projected Trajectory
#       plot:                             (bool) Plot the Projected Trajectory
#       num_bins:                         (int) Number of bins for the Kernel Density Estimation of the Projected Trajectory
#       bandwidth:                        (float) Bandwidth for the Kernel Density Estimation of the Projected Trajectory
#       alpha:                            (float) Transparency of the points in the Projected Trajectory
#       cmap:                             (str) Colormap for the Projected Trajectory
#       use_legend:                        (bool) Use a legend in the Projected Clustered Trajectory plot
#       marker_size:                      (int) Size of the markers in the Projected Trajectory
#   clustering:                        Settings for the clustering
#     run:                              (bool) Whether to run the clustering or not
#     algorithm:                        (str: kmeans, hdbscan, hierarchical) Clustering algorithm to use
#     opt_num_clusters:                 (bool) Whether to search for the optimal number of clusters inside the search_interval or not (only for hierarchical and kmeans)
#     search_interval:                  (list) Range of number of clusters to search for the optimal number of clusters (only for hierarchical and kmeans)
#     num_clusters:                     (int) Number of clusters to use (only for hierarchical and kmeans and if opt_num_clusters is false)
#     linkage:                          (str) Linkage criterion to use ('ward', 'single', 'average', 'complete') (only for hierarchical)
#     n_init:                           (int) Number of times the k-means algorithm is run with different centroid seeds (only for kmeans)
#     min_cluster_size:                 (int) Minimum number of samples in a group for that group to be considered a cluster; groupings smaller than this size will be left as noise (only for hdbscan)
#     max_cluster_size:                 (int) Maximum number of samples in a group for that group to be considered a cluster; If null, there is no limit (only for hdbscan)
#     min_samples:                      (int) Number of samples in a neighborhood for a point to be considered as a core point (only for hdbscan)
#     cluster_selection_epsilon:        (float) A distance threshold. Clusters below this value will be merged (only for hdbscan)
#     cluster_selection_method:         (str) Method to select the number of clusters ('eom', 'leaf') (only for hdbscan)
#
#   Note that:
#     min_cluster_size should be set to the smallest size grouping that you wish to consider a cluster.
#     the larger the value of min_samples you provide, the more conservative the clustering (more points will be declared as noise) and clusters will be restricted to progressively more dense areas

train_colvars:
  cvs: ['pca', 'ae', 'htica', 'deep_tica']
  common:
    dimension: 2
    num_subspaces: 10
    subspaces_dimension: 5
    features_normalization: 'mean_std'
    input_colvars: 
      start: 0
      stop: null
      stride: 1 
    architecture:
      hidden_layers: [15, 15] # Increase the complexity if needed: [100, 50, 20]
      lag_time: 1
    training: 
      general:
        max_tries: 10
        seed: 42
        lengths: [0.8, 0.2]
        batch_size: 264
        max_epochs: 5000    
        dropout: 0.1
        shuffle: True
        random_split: True
        check_val_every_n_epoch: 1
        save_check_every_n_epoch: 1
      early_stopping:
        patience: 100
        min_delta: 1.0e-05
      optimizer:
        name: Adam
        kwargs: 
          lr: 1.0e-05
          weight_decay: 0.0
      save_loss: True
      plot_loss: True
  figures:
    fes:
      compute: True  
      save: True  
      temperature: 300
      bandwidth: 0.025
      num_bins: 200
      num_blocks: 1
      max_fes: 18
    traj_projection:
      plot: True
      num_bins: 100
      bandwidth: 0.25
      alpha: 0.6
      cmap: turbo
      use_legend: True
      marker_size: 12
  clustering:                        
    run: False                        
    algorithm: hdbscan               
    opt_num_clusters: True          
    search_interval: [3, 8]          
    num_clusters: 3                  
    linkage: complete                
    n_init: 20                       
    min_cluster_size: 50             
    min_samples: 5                  
    cluster_selection_epsilon: 0
